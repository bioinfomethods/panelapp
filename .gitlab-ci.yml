include:
  - local: '.gitlab-ci/envs.yml'
  - template: Code-Quality.gitlab-ci.yml

variables:
  DOCKER_TERRAFORM: hashicorp/terraform:1.4.6
  DOCKER_TERRAFORM_OLD: hashicorp/terraform:0.11.15
  DOCKER_PYTHON: python:3.8.17-alpine3.18
  DOCKER_POSTGRES: postgres:14.7
  DOCKER_IN_DOCKER: docker:23.0.3-dind
  PANELAPP_TF_DIR: "panelapp-infra/terraform/panelapp/"
  AWS_REGION: eu-west-2
  AWS_DEFAULT_REGION: eu-west-2
  CI_DEBUG_TRACE: "false"
  AWS_ASSUME_ROLE: "arn:aws:iam::${AWS_ACCOUNT_ID}:role/CIDeploypanelapp"
  ECR_ACCOUNT_ID: 577192787797
  ECR_REGISTRY: "${ECR_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com"
  ECR_ASSUME_ROLE: "arn:aws:iam::${ECR_ACCOUNT_ID}:role/CIDeploypanelapp"
  ECR_REPOSITORY: panelapp
  WORKFLOW_NAME: "Deploying app: $version, infra: $infra_version -> $deploy_name"
  TAGGER_REGISTRY: $ECR_ACCOUNT_ID
  TAGGER_REPOSITORY: $ECR_REPOSITORY
  TAGGER_ENVIRONMENTS: "build,dev,dev_old,test,test_old,e2e,uat,uat_old,prod,prod_old"
#  TAGGER_DEBUG: 'yes'
  deploy_name:
    description: "Environment to deploy to"
    value: dev
    options:
      - dev
      - dev_old
      - test
      - e2e
      - "--- regulated environments ---"
      - test_old
      - uat
      - uat_old
      - prod
      - prod_old
  env_name: $deploy_name
  account_group: new
  version:
    description: "Version to deploy"
    value: 3.4.0-alpha.22
  infra_version_new:
    description: "Infra version (tag or branch) to use"
    value: 2.0.0-alpha.11
  infra_version_old:
    description: "Infra version (tag or branch) to use"
    value: 1.1.0-alpha.2
  deploy_runner: pool_name:panelapp_docker

stages:
  - test
  - image_build
  - plan
  - apply

default:
  tags:
    - pool_name:panelapp_docker

.deploy:
  image:
    name: $DOCKER_TERRAFORM
    entrypoint: ["/bin/sh", "-c"]
  tags:
    - $deploy_runner
  before_script:
    - apk --no-cache add --update python3 curl jq aws-cli py3-boto3
    - test "$account_group" = new || curl -sSf http://169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI -o aws_creds
    - test "$account_group" = new || export AWS_ACCESS_KEY_ID=$(jq -r '.AccessKeyId' aws_creds)
    - test "$account_group" = new || export AWS_SECRET_ACCESS_KEY=$(jq -r '.SecretAccessKey' aws_creds)
    - test "$account_group" = new || export AWS_SESSION_TOKEN=$(jq -r '.Token' aws_creds)
    - test "$account_group" = new || export AWS_DEFAULT_REGION=$default_region

.tests:
  image: $DOCKER_PYTHON
  stage: test
  services:
    - name: $DOCKER_IN_DOCKER
      command:
        - "--registry-mirror"
        - "http://dockerhubcache.shared-services.aws.gel.ac:5002"
  rules:
    - if: $TEST

.tag:
  image: $DOCKER_IN_DOCKER
  before_script:
    - apk add aws-cli jq py3-boto3
    - source scripts/assume_role.sh
  variables:
    AWS_ASSUME_ROLE: $ECR_ASSUME_ROLE

code_quality:
  extends: .tests
  artifacts:
    paths: [gl-code-quality-report.json]
  rules:
    - if: $TEST

# Code checks
## run unit and integration tests
code_test:
  extends: .tests
  coverage: /^TOTAL.+?(\d+\%)$/
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
  services:
    - name: $DOCKER_POSTGRES
      alias: db-postgres
  variables:
    POSTGRES_DB: panelapp
    POSTGRES_USER: panelapp
    POSTGRES_PASSWORD: secret
    DATABASE_URL: postgres://panelapp:secret@db-postgres:5432/panelapp
    DJANGO_SETTINGS_MODULE: panelapp.settings.test
    DJANGO_LOG_LEVEL: INFO
  before_script:
    - apk add --no-cache postgresql-libs git curl jpeg-dev zlib-dev gcc musl-dev curl-dev postgresql-dev build-base linux-headers libffi-dev
    - python -m venv .venv
    - source .venv/bin/activate
    - pip install .[tests]
    - pip install pytest-runner
  script:
    - pytest --cov-report term --cov-report xml

## Linting, formatting, etc
import_sorting:
  extends: .tests
  before_script:
    - python -m venv .venv
    - source .venv/bin/activate
    - pip install isort==5.0.5
  script:
    - isort . -c

formatter:
  extends: .tests
  before_script:
    - python -m venv .venv
    - source .venv/bin/activate
    - pip install black==22.3.0
  script:
    - black . --check

trivy:
  stage: test
  image:
    name: aquasec/trivy:0.42.1
    entrypoint: [""]
  script:
    - trivy fs --exit-code 0 --cache-dir .trivycache/ --severity MEDIUM,HIGH,CRITICAL --ignore-unfixed --format template --template "@/contrib/junit.tpl" -o trivy.junit.xml .
    - trivy fs --exit-code 1 --cache-dir .trivycache/ --severity CRITICAL --ignore-unfixed --no-progress .
    - if [[ -s .trivyignore ]]; then echo ".trivyignore is not empty" ; cat .trivyignore ; exit 2 ; fi
  allow_failure:
    exit_codes:
      - 2 # warn when .trivyignore exists and is not empty
  rules:
    - if: $TEST
      allow_failure: true
      when: never
  artifacts:
    when: always
    reports:
      junit: "trivy.junit.xml"
    paths:
      - "trivy.junit.xml"

# Build docker image
image_build:
  image: $DOCKER_IN_DOCKER
  services:
    - name: $DOCKER_IN_DOCKER
      command:
        - "--registry-mirror"
        - "http://dockerhubcache.shared-services.aws.gel.ac:5002"
  stage: image_build
  before_script:
    - apk add aws-cli jq py3-boto3
    - source scripts/assume_role.sh
  script:
    - build_tag="ci-$CI_JOB_ID"
    - '(scripts/tagger validate-version "$CI_COMMIT_TAG" && ! scripts/tagger tag-exists "$CI_COMMIT_TAG") || scripts/tagger freestyle-tag "$CI_COMMIT_TAG"'
    - aws ecr get-login-password --region eu-west-2 | docker login --username AWS --password-stdin "$ECR_REGISTRY"
    - echo "${CI_COMMIT_TAG}" > ./VERSION
    - docker build -t "$ECR_REGISTRY/$ECR_REPOSITORY:$build_tag" --file ./docker/cloud/Dockerfile .
    - docker push "$ECR_REGISTRY/$ECR_REPOSITORY:$build_tag"
    - scripts/tagger add-env-tags --env=build --add-latest=1 "$build_tag"
    - scripts/tagger add-tag "$build_tag" "$CI_COMMIT_TAG"
  variables:
    AWS_ASSUME_ROLE: $ECR_ASSUME_ROLE
  rules:
    - if: $CI_COMMIT_TAG != null

# Deploy all the things

check_version:
  stage: plan
  extends: .tag
  script:
    - "printf '###\n### checking application version: %s\n###\n' \"$version\""
    - scripts/tagger tag-exists "$version"
    - test "$env_name" != e2e || scripts/tagger validate-version "$version"
    - test "$env_name" != uat || scripts/tagger validate-version --no-alpha --no-beta "$version"
    - test "$env_name" != prod || scripts/tagger validate-version --no-alpha --no-beta --no-rc "$version"
    - "printf '###\n### checking infrastructure version: %s\n###\n' \"$infra_version\""
    - test "$env_name" != e2e || scripts/tagger validate-version "$infra_version"
    - test "$env_name" != uat || scripts/tagger validate-version --no-alpha --no-beta "$infra_version"
    - test "$env_name" != prod || scripts/tagger validate-version --no-alpha --no-beta --no-rc "$infra_version"
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_COMMIT_TAG != null

scan:
  stage: plan
  dependencies:
    - image_build
  environment:
    name: $deploy_name
  image: 877059142592.dkr.ecr.eu-west-2.amazonaws.com/ce_infra_cicd:v1.0.6
  before_script:
    - apk add aws-cli jq py3-boto3
    - source scripts/assume_role.sh
  script:
    - aws ecr describe-image-scan-findings --repository-name "$ECR_REPOSITORY" --image-id imageTag="$version" | tee "inspector_findings_$version.json"
    - count_findings () { jq ".imageScanFindings.findingSeverityCounts.$1 // 0" "inspector_findings_$version.json"; }
    - |
      if [ "$(count_findings CRITICAL)" -gt 0 ]; then
        echo -e "\e[91mThe image "$ECR_REPOSITORY:$version" has $(count_findings CRITICAL) CRITICAL findings.\e[0m"
        exit 101
      elif [ "$(count_findings HIGH)" -gt 0 ]; then
        echo -e "\e[93mThe image "$ECR_REPOSITORY:$version" has $(count_findings HIGH) HIGH findings.\e[0m"
        exit 102
      else
        echo -e "\e[92mAll good!\e[0m"
      fi
  variables:
    AWS_ASSUME_ROLE: $ECR_ASSUME_ROLE
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_COMMIT_TAG != null
  allow_failure:
    exit_codes:
      - 101
      - 102
  artifacts:
    paths:
      - inspector_findings_$version.json
    when: on_failure

plan:
  stage: plan
  extends: .deploy
  environment:
    name: $deploy_name
  dependencies:
    - image_build
  script:
    - printf '###\n### terraform plan\n###\n'
    - git clone --single-branch --branch "$infra_version" https://$TF_CODE_REPO_USER:$TF_CODE_REPO_TOKEN@gitlab.com/genomicsengland/panelapp/panelapp-infra.git
    - cd "$PANELAPP_TF_DIR"
    - terraform init -backend-config="../config/$env_name/panelapp-backend.conf"
    - terraform plan -var-file="../config/$env_name/terraform.tfvars" -var image_tag="$version" -out=plan.tfplan
    - "printf '### Environment: %s\n### Version: %s\n' \"$deploy_name\" \"$version\""
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_COMMIT_TAG != null
  artifacts:
    paths:
      - $PANELAPP_TF_DIR/.terraform*
      - $PANELAPP_TF_DIR/plan.*
      - $PANELAPP_TF_DIR/*.zip
      - $PANELAPP_TF_DIR/templates/*
      - panelapp-infra/*.py

apply:
  stage: apply
  extends: .deploy
  environment:
    name: $deploy_name
  dependencies:
    - plan
    - scan
  script:
    - cd "$PANELAPP_TF_DIR"
    - terraform apply plan.tfplan
    - cd -
    - test "$account_group" = old || source scripts/assume_role.sh
    - time aws ecs wait services-stable --cluster panelapp-cluster-$env_name --services panelapp-web-panelapp-$env_name panelapp-worker-panelapp-$env_name panelapp-worker-beat-panelapp-$env_name
    - panelapp-infra/run-ecs-task.py panelapp-migrate-panelapp-$env_name panelapp-collectstatic-panelapp-$env_name
    - sleep 30
    - test "$env_name" = "prod" || panelapp-infra/run-ecs-task.py panelapp-datacleanup-$env_name
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_COMMIT_TAG != null
      when: manual

add_tags:
  stage: apply
  extends: .tag
  needs:
    - apply
  script:
    - scripts/tagger add-env-tags --env="$deploy_name" --add-latest=3 "$version"
    - scripts/tagger --verbose list-tags
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_COMMIT_TAG != null
